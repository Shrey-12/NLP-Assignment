{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b9cb82-3479-4456-88e7-d0f6fb8fbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import contractions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3e5de2-f2f0-4b16-8d42-57c166d2a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rt-polaritydata/rt-polarity.neg', 'r', encoding='ISO-8859-1') as f:\n",
    "    neg_reviews = f.readlines()\n",
    "\n",
    "with open('rt-polaritydata/rt-polarity.pos', 'r', encoding='ISO-8859-1') as f:\n",
    "    pos_reviews = f.readlines()\n",
    "\n",
    "neg_reviews = pd.DataFrame(neg_reviews, columns=['text'])\n",
    "pos_reviews = pd.DataFrame(pos_reviews, columns=['text'])\n",
    "neg_reviews['label'] = 0\n",
    "pos_reviews['label'] = 1\n",
    "reviews = pd.concat([neg_reviews, pos_reviews], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6036dbd8-c6c2-4bda-9bf9-6e483cdff79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def pre_processing(rev):\n",
    "    rev = expand_contractions(rev)\n",
    "    return rev \n",
    "\n",
    "pos_reviews['preprocessed_review'] = pos_reviews['text'].apply(pre_processing)\n",
    "neg_reviews['preprocessed_review'] = neg_reviews['text'].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e0414e-74fb-477c-b2ca-ff86d7277b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = pos_reviews.iloc[:4000]\n",
    "train_neg = neg_reviews.iloc[:4000]\n",
    "train_data = pd.concat([train_pos['preprocessed_review'], train_neg['preprocessed_review']], ignore_index=True)\n",
    "train_labels = pd.concat([train_pos['label'], train_neg['label']], ignore_index=True)\n",
    "\n",
    "val_pos = pos_reviews.iloc[4000:4500]\n",
    "val_neg = neg_reviews.iloc[4000:4500]\n",
    "val_data = pd.concat([val_pos['preprocessed_review'], val_neg['preprocessed_review']], ignore_index=True)\n",
    "val_labels = pd.concat([val_pos['label'], val_neg['label']], ignore_index=True)\n",
    "\n",
    "test_pos = pos_reviews.iloc[4500:]\n",
    "test_neg = neg_reviews.iloc[4500:]\n",
    "test_data = pd.concat([test_pos['preprocessed_review'], test_neg['preprocessed_review']], ignore_index=True)\n",
    "test_labels = pd.concat([test_pos['label'], test_neg['label']], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fef9297c-d1a9-4867-94fc-189e7bbfe8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_function(train_data)\n",
    "val_encodings = tokenize_function(val_data)\n",
    "test_encodings = tokenize_function(test_data)\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels.values))\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels.values))\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels.values))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da73efd4-c590-499c-b1f1-d45665750f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1) \n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return torch.sigmoid(self.fc2(self.fc1(pooled_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb6a201e-a41b-446f-903c-03ebb67a33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cb0a105-c4fe-4a42-ad49-ac1426babb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62275d32-a28f-46e9-bdbe-0368293e11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}'):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}')\n",
    "        val_loss, val_f1 = evaluate_model(model, val_loader, criterion)\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation F1 Score: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b66d22b-d473-4193-be30-3ee79db22156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Evaluating'):\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs >= 0.5).int()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_predictions, target_names=[\"Negative\", \"Positive\"]))\n",
    "\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5465088c-35ea-4eed-aeab-30e1a8ab4770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|███████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.87      0.88       500\n",
      "    Positive       0.88      0.89      0.88       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "Validation Loss: 0.2949, Validation F1 Score: 0.8830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|███████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.85      0.89       500\n",
      "    Positive       0.86      0.93      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "Validation Loss: 0.3041, Validation F1 Score: 0.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|███████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.88      0.89       500\n",
      "    Positive       0.88      0.90      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "Validation Loss: 0.3643, Validation F1 Score: 0.8910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c10e950f-df8a-4807-843e-496dabdda178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.88      0.89       500\n",
      "    Positive       0.88      0.90      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36430347454734147, 0.8909815758863249)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model,val_loader,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd373a-2317-4bd7-890e-b5434276f8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
